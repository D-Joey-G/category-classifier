{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South Korea's longest river, the Nakdong, flow...</td>\n",
       "      <td>Busan or Pusan</td>\n",
       "      <td>Geography</td>\n",
       "      <td>South Korea's longest river, the Nakdong, flow...</td>\n",
       "      <td>south koreas longest river the nakdong flows t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Developed by Francophone writers and politicia...</td>\n",
       "      <td>Aime Cesaire</td>\n",
       "      <td>Art and Literature</td>\n",
       "      <td>Developed by Francophone writers and politicia...</td>\n",
       "      <td>developed by francophone writers and politicia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Argonauts of the Western Pacific, Bronislaw...</td>\n",
       "      <td>Kula or Kula ring or Kula exchange</td>\n",
       "      <td>Geography</td>\n",
       "      <td>In Argonauts of the Western Pacific, Bronislaw...</td>\n",
       "      <td>in argonauts of the western pacific bronislaw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the deficiencies of the Standard Model ...</td>\n",
       "      <td>weak and gravity</td>\n",
       "      <td>Science and Nature</td>\n",
       "      <td>One of the deficiencies of the Standard Model ...</td>\n",
       "      <td>one of the deficiencies of the standard model ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Appearing in the title of a 1982 book by evolu...</td>\n",
       "      <td>phenotype</td>\n",
       "      <td>Science and Nature</td>\n",
       "      <td>Appearing in the title of a 1982 book by evolu...</td>\n",
       "      <td>appearing in the title of a 1982 book by evolu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  South Korea's longest river, the Nakdong, flow...   \n",
       "1  Developed by Francophone writers and politicia...   \n",
       "2  In Argonauts of the Western Pacific, Bronislaw...   \n",
       "3  One of the deficiencies of the Standard Model ...   \n",
       "4  Appearing in the title of a 1982 book by evolu...   \n",
       "\n",
       "                               Answer            Category  \\\n",
       "0                      Busan or Pusan           Geography   \n",
       "1                        Aime Cesaire  Art and Literature   \n",
       "2  Kula or Kula ring or Kula exchange           Geography   \n",
       "3                    weak and gravity  Science and Nature   \n",
       "4                           phenotype  Science and Nature   \n",
       "\n",
       "                                                text  \\\n",
       "0  South Korea's longest river, the Nakdong, flow...   \n",
       "1  Developed by Francophone writers and politicia...   \n",
       "2  In Argonauts of the Western Pacific, Bronislaw...   \n",
       "3  One of the deficiencies of the Standard Model ...   \n",
       "4  Appearing in the title of a 1982 book by evolu...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  south koreas longest river the nakdong flows t...  \n",
       "1  developed by francophone writers and politicia...  \n",
       "2  in argonauts of the western pacific bronislaw ...  \n",
       "3  one of the deficiencies of the standard model ...  \n",
       "4  appearing in the title of a 1982 book by evolu...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Setup\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# 2. Load cleaned data\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "#  Inspect\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'Art and Literature': 0, 'Entertainment': 1, 'Geography': 2, 'History': 3, 'Lifestyle': 4, 'Music': 5, 'Science and Nature': 6, 'Sport': 7}\n"
     ]
    }
   ],
   "source": [
    "# 3. Extract features and labels\n",
    "X_raw = df[\"clean_text\"]\n",
    "y_raw = df[\"Category\"]\n",
    "\n",
    "# Encode labels as integers\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_raw)\n",
    "\n",
    "# See encoded labels\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Mapping:\", label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Split into train/test sets\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_raw, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tfidf vectorizer and X for max_features=5000\n",
      "Saved tfidf vectorizer and X for max_features=10000\n",
      "Saved tfidf vectorizer and X for max_features=20000\n",
      "Saved count vectorizer and X for max_features=5000\n",
      "Saved count vectorizer and X for max_features=10000\n",
      "Saved count vectorizer and X for max_features=20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['y_test.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Tokenize + Vectorize + Save\n",
    "\n",
    "# Both TF-IDF and CountVectorizer to see which performs better \n",
    "vectorizer_types = {\n",
    "    \"tfidf\": TfidfVectorizer,\n",
    "    \"count\": CountVectorizer\n",
    "}\n",
    "\n",
    "# Range of max_features to see if any lead to better outcomes \n",
    "max_features_list = [5000, 10000, 20000]\n",
    "\n",
    "for vtype, VectClass in vectorizer_types.items():\n",
    "    for n in max_features_list:\n",
    "        vect = VectClass(\n",
    "            max_features=n,\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words=\"english\"\n",
    "        )\n",
    "        X_train = vect.fit_transform(X_train_raw)\n",
    "        X_test = vect.transform(X_test_raw)\n",
    "\n",
    "        # Save vectorizer and matrix\n",
    "        joblib.dump(vect, f\"vectorizer_{vtype}_{n}.joblib\")\n",
    "        joblib.dump(X_train, f\"X_train_{vtype}_{n}.joblib\")\n",
    "        joblib.dump(X_test, f\"X_test_{vtype}_{n}.joblib\")\n",
    "\n",
    "        print(f\"Saved {vtype} vectorizer and X for max_features={n}\")\n",
    "\n",
    "# Save y only once\n",
    "joblib.dump(y_train, \"y_train.joblib\")\n",
    "joblib.dump(y_test, \"y_test.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tfidf vectorizer and X for max_features=30000\n",
      "Saved tfidf vectorizer and X for max_features=40000\n",
      "Saved tfidf vectorizer and X for max_features=50000\n",
      "Saved count vectorizer and X for max_features=30000\n",
      "Saved count vectorizer and X for max_features=40000\n",
      "Saved count vectorizer and X for max_features=50000\n"
     ]
    }
   ],
   "source": [
    "max_features_list = [30000, 40000, 50000]\n",
    "\n",
    "for vtype, VectClass in vectorizer_types.items():\n",
    "    for n in max_features_list:\n",
    "        vect = VectClass(\n",
    "            max_features=n,\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words=\"english\"\n",
    "        )\n",
    "        X_train = vect.fit_transform(X_train_raw)\n",
    "        X_test = vect.transform(X_test_raw)\n",
    "\n",
    "        # Save vectorizer and matrix\n",
    "        joblib.dump(vect, f\"vectorizer_{vtype}_{n}.joblib\")\n",
    "        joblib.dump(X_train, f\"X_train_{vtype}_{n}.joblib\")\n",
    "        joblib.dump(X_test, f\"X_test_{vtype}_{n}.joblib\")\n",
    "\n",
    "        print(f\"Saved {vtype} vectorizer and X for max_features={n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved TF-IDF vectorizer and matrices for max_features=75000\n",
      "✅ Saved TF-IDF vectorizer and matrices for max_features=100000\n",
      "✅ Saved TF-IDF vectorizer and matrices for max_features=150000\n",
      "✅ Saved TF-IDF vectorizer and matrices for max_features=200000\n",
      "✅ Saved TF-IDF vectorizer and matrices for max_features=250000\n",
      "✅ Saved TF-IDF vectorizer and matrices for max_features=300000\n",
      "✅ Saved TF-IDF vectorizer and matrices for max_features=350000\n",
      "✅ Saved TF-IDF vectorizer and matrices for max_features=400000\n"
     ]
    }
   ],
   "source": [
    "# Higher feature limits for further testing\n",
    "\n",
    "max_features_list = [75000, 100000, 150000, 200000, 250000, 300000, 350000, 400000]\n",
    "\n",
    "for n in max_features_list:\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=n,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=\"english\"\n",
    "    )\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train_raw)\n",
    "    X_test = vectorizer.transform(X_test_raw)\n",
    "\n",
    "    # Save vectorizer and transformed matrices\n",
    "    joblib.dump(vectorizer, f\"vectorizer_tfidf_{n}.joblib\")\n",
    "    joblib.dump(X_train, f\"X_train_tfidf_{n}.joblib\")\n",
    "    joblib.dump(X_test, f\"X_test_tfidf_{n}.joblib\")\n",
    "\n",
    "    print(f\"✅ Saved TF-IDF vectorizer and matrices for max_features={n}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full feature count: 427290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['X_test_tfidf_full.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unlimited featuress\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    "    # no max_features\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "\n",
    "print(f\"Full feature count: {X_train.shape[1]}\")  # Should be ~427,290\n",
    "\n",
    "# Save as usual\n",
    "joblib.dump(vectorizer, \"vectorizer_tfidf_full.joblib\")\n",
    "joblib.dump(X_train, \"X_train_tfidf_full.joblib\")\n",
    "joblib.dump(X_test, \"X_test_tfidf_full.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Save encoded labels\n",
    "\n",
    "joblib.dump(label_encoder, \"label_encoder.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
